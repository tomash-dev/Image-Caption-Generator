<h1>Image Caption Generator</h1>

A Neural Network to generate captions for an image.

<p align="center">
  <strong>Examples</strong>
</p>

<p align="center">
  <img src="https://cdn-images-1.medium.com/max/1600/1*6BFOIdSHlk24Z3DFEakvnQ.png" width="75%" title="Example of Image Captioning" alt="Example of Image Captioning">
</p>

<p align="center">
  <strong>Credits : <a href="https://towardsdatascience.com/image-captioning-in-deep-learning-9cd23fb4d8d2">Towardsdatascience</a></strong>
</p>

<h1>Requirements</h1>

Recommended System Requirements to train model.

<ul type="square">
	<li>A good CPU and a GPU</li>
	<li>Atleast 8gb of RAM</li>
</ul>

Required Libraries for python

<ul type="square">
	<li>Keras</li>
	<li>Pillow</li>
	<li>nltk</li>
	<li>Matplotlib</li>
</ul>

Flickr8k Dataset: <a href="https://forms.illinois.edu/sec/1713398">Dataset Request Form</a>

<strong>Important:</strong> After downloading the dataset, put the reqired files in train_val_data folder

<h1>Procedure to Train Model</h1>
<ol>
	<li>Clone the repository to preserve directory structure</li>
	<li>Put the required files in train_val_data Folder</li>
	<li>Run train_val.py</li>
</ol>

<h1>Procedure to Test on new images</h1>
<ol>
	<li>Clone the repository to preserve directory structure</li>
	<li>Put the test image in test_data folder</li>
	<li>Run test.py</li>
</ol>

<h1>References</h1>

<ul type="square">
	<li><a href="https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Vinyals_Show_and_Tell_2015_CVPR_paper.pdf">Show and Tell: A Neural Image Caption Generator</a> - Oriol Vinyals, Alexander Toshev, Samy Bengio, Dumitru Erhan</li>
</ul>
